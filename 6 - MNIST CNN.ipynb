{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION TO CNN USING TENSORFLOW\n",
    "\n",
    "### BASIC EXAMPLE\n",
    "\n",
    "![BASIC CNN](./images/cnn-basic-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: IMPORT LIBRARY AND LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: CREATE AN INTERACTIVE SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: DEFINE THE SHAPE OF OUR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: DEFINE HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. FOR WEIGHTS AND BIASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = lambda shape: tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "b = lambda shape: tf.Variable(tf.constant(0.1, shape=shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. FOR CONVOLUTION AND POOLING LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: DEFINE MODEL\n",
    "\n",
    "#### OPTIMISATION 1:\n",
    "\n",
    "- Uptil now we have been ignoring one pattern which has been in our dataset... That is the spatial data...\n",
    "- That is if instead of considering the input data points as independant data units... let's us consider that these points are dependant on their neighbours and think of the data as a 2d array of pixels.\n",
    "- CNNs exploit this spatial factor to improve the accuracy of any model provided the data points have inherent spatial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAYER 1: CONVOLUTIONAL LAYER WITH MAX POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = W(shape=[5, 5, 1, 32])\n",
    "b_conv1 = b(shape=[32])\n",
    "x_conv1 = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "conv1 = tf.nn.relu(conv2d(x_conv1, W_conv1) + b_conv1)\n",
    "pool1 = max_pool_2x2(conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAYER 2: CONVOLUTIONAL LAYER WITH MAX POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = W(shape=[5, 5, 32, 64])\n",
    "b_conv2 = b(shape=[64])\n",
    "\n",
    "conv2 = tf.nn.relu(conv2d(pool1, W_conv2) + b_conv2)\n",
    "pool2 = max_pool_2x2(conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAYER 3: DENSELY CONNECTED LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = W(shape=[7 * 7 * 64, 1024])\n",
    "b_fc1 = b(shape=[1024])\n",
    "\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "fc1 = tf.nn.relu(tf.matmul(pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "fc1_drop = tf.nn.dropout(fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAYER 4: READOUT LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = W(shape=[1024, 10])\n",
    "b_fc2 = b(shape=[10])\n",
    "\n",
    "y_conv = tf.matmul(fc1, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: DEFINE METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. LOSS IN THE FORM OF CROSS ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TRAINING USING ADAM OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    learning_rate=0.01,\n",
    "    global_step=global_step,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ACCURACY OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0 : ACCURACY 0.22\n",
      "STEP 100 : ACCURACY 0.98\n",
      "STEP 200 : ACCURACY 0.98\n",
      "STEP 300 : ACCURACY 0.98\n",
      "STEP 400 : ACCURACY 1.0\n",
      "STEP 500 : ACCURACY 0.94\n",
      "STEP 600 : ACCURACY 0.98\n",
      "STEP 700 : ACCURACY 0.96\n",
      "STEP 800 : ACCURACY 0.98\n",
      "STEP 900 : ACCURACY 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50) \n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    \n",
    "    ### TEST OUR MODEL INBETWEEN\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={ x: batch[0], y_: batch[1], keep_prob: 1 })\n",
    "        print('STEP', i, ':', 'ACCURACY', train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 8: EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL ACCURACY: 0.9751\n"
     ]
    }
   ],
   "source": [
    "final_accuracy = accuracy.eval(feed_dict={ x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1 })\n",
    "print('FINAL ACCURACY:', final_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 9: TEST PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL VALUE: [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x_actual = mnist.test.images[0:1]\n",
    "y_actual = mnist.test.labels[0:1]\n",
    "\n",
    "print('ACTUAL VALUE:', y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED VALUE: [[  2.41497111   0.27594382   6.96642971   5.32868099   2.03751612\n",
      "    2.52723384  -4.13650703  16.62407684   3.11290574   5.37490654]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = sess.run(y_conv, feed_dict={x: x_actual, keep_prob: 1})\n",
    "\n",
    "print('PREDICTED VALUE:', y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED OUTPUT: [7]\n",
      "PREDICTED OUTPUT: [7]\n"
     ]
    }
   ],
   "source": [
    "output_actual = sess.run(tf.argmax(y_actual, 1))\n",
    "output_predicted = sess.run(tf.argmax(y_predicted, 1))\n",
    "\n",
    "print ('EXPECTED OUTPUT:', output_actual)\n",
    "print ('PREDICTED OUTPUT:', output_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
